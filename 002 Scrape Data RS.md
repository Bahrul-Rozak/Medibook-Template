# JUDUL: Cara Scrape Data Rumah Sakit dari Google Maps dalam 5 Menit (Python + Selenium)

**Durasi:** 200 detik  
**Gaya:** Storytelling teknis dengan bahasa santai, mudah dipahami pemula

---

## ğŸ“‹ BREAKDOWN DETIK-DEMI-DETIK

### **HOOK (0â€“15 detik)**

| Waktu | Narasi | Visual |
|-------|--------|--------|
| 0â€“5 | Lo pernah kepikiran nggak... gimana cara ambil data rumah sakit dari Google Mapsâ€”otomatis, tanpa manual copy-paste? | Tunjuk Google Maps di browser |
| 6â€“10 | Bayangin lo harus kumpulin 100 rumah sakit di Sumatera Utara... manual? Capek banget, bro! | Gesture "capek banget" |
| 11â€“15 | Nah, hari ini gue bakal kasih tau cara otomatisin itu pake Python + Selenium dalam 5 menit aja! | Senyum, jari tunjuk layar |

---

### **CHAPTER 1: Apa Itu Web Scraping dengan Selenium? (15â€“50 detik)**

| Waktu | Narasi | Visual |
|-------|--------|--------|
| 15â€“22 | Selenium itu kayak robot yang bisa kontrol browser lo. Lo kasih perintah, dia yang klik, scroll, ambil dataâ€”otomatis! | Gesture "robot" |
| 23â€“30 | Bedanya sama library scraping biasa? Selenium bisa handle website yang pake JavaScript beratâ€”kayak Google Maps yang dinamis banget. | Tunjuk loading Google Maps |
| 31â€“38 | Jadi kalau website-nya butuh klik tombol, scroll halaman, atau tunggu animasiâ€”Selenium jagoannya! | Gesture "scroll" |
| 39â€“45 | Tools yang kita pake: Python + Selenium + ChromeDriver. Semua gratis, open-source, dan powerful banget. | Tunjuk logo Python & Chrome |
| 46â€“50 | *(jeda napas)* | Ambil napas, minum air |

---

### **CHAPTER 2: Setup Awal â€” Install Library (50â€“90 detik)**

| Waktu | Narasi | Visual |
|-------|--------|--------|
| 50â€“58 | Pertama, lo harus punya Python udah terinstall. Belum? Download di python.orgâ€”gratis. Cek pake `python --version` di terminal. | Tunjuk website python.org |
| 59â€“66 | Lalu buka terminal atau CMD, install 3 library penting ini satu per satu: | Hitung pakai jari |
| 67â€“72 | Pertama: `pip install selenium` â€”ini library utamanya buat otomatisasi browser. | Ketik di terminal |
| 73â€“78 | Kedua: `pip install webdriver-manager` â€”biar ChromeDriver otomatis update, nggak perlu download manual. | Ketik lagi |
| 79â€“83 | Ketiga: `pip install csv` â€”untuk export data ke file CSV (biasanya udah ada di Python). | Ketik lagi |
| 84â€“90 | Kalau udah semua, buat file baru namanya `scrape_hospital.py`. Bisa pake VS Code, PyCharm, atau Notepad++â€”bebas. | Buka code editor, buat file baru |

---

### **CHAPTER 3: Breakdown Kode â€” Baris demi Baris (90â€“170 detik)**

| Waktu | Narasi | Visual |
|-------|--------|--------|
| 90â€“97 | Oke, sekarang kita bahas kode-nya. Baris pertama: `from selenium import webdriver` â€”ini buat import library Selenium yang tadi udah kita install. | Highlight baris 1 di code |
| 98â€“105 | Baris kedua & ketiga: import Service dan By â€”ini buat setup driver dan cara cari elemen di website. | Highlight baris 2-3 |
| 106â€“113 | Baris keempat: `from webdriver_manager.chrome import ChromeDriverManager` â€”ini yang bikin ChromeDriver otomatis install & update. Gila praktis! | Highlight baris 4 |
| 114â€“120 | Baris kelima & enam: import time dan csv â€”time buat kasih jeda, csv buat export data nanti. | Highlight baris 5-6 |
| 121â€“130 | Nah, bagian setup WebDriver. Ada 2 mode: **headless** (browser jalan di background, nggak kelihatan) atau **normal** (browser terbuka, lo bisa liat prosesnya). | Gesture "lihat proses" |
| 131â€“138 | Di kode ini, gue comment dulu mode headless-nya biar lo bisa liat proses scraping berjalan. Kalau udah jago, uncomment buat bikin lebih cepat. | Tunjuk comment di code |
| 139â€“146 | Baris `driver = webdriver.Chrome(...)` â€”ini yang bikin Chrome terbuka otomatis. ChromeDriverManager otomatis download driver yang sesuai versi Chrome lo. | Highlight baris setup driver |
| 147â€“154 | `url = 'https://www.google.com/search?q=rs+di+Sumatera+Utara...'` â€”ini target pencarian Google Maps. Lo bisa ganti keyword-nya sesuai kebutuhan. | Highlight URL |
| 155â€“162 | `driver.get(url)` â€”perintah buat buka URL tersebut di browser. `time.sleep(3)` â€”tunggu 3 detik biar halaman selesai loading. | Highlight baris get & sleep |
| 163â€“170 | `all_results = []` â€”list kosong buat nyimpen semua data rumah sakit yang kita ambil. | Highlight list kosong |

---

### **CHAPTER 4: Logika Scraping â€” Ambil Data dari Setiap Halaman (170â€“230 detik)**

| Waktu | Narasi | Visual |
|-------|--------|--------|
| 170â€“178 | Sekarang masuk ke bagian inti: loop `while True`. Ini artinya program bakal jalan terus sampe ketemu break. | Highlight while loop |
| 179â€“186 | `results = driver.find_elements(By.CLASS_NAME, 'VkpGBb')` â€”ini nyari semua elemen rumah sakit di halaman. Class 'VkpGBb' itu class khusus Google buat hasil pencarian. | Highlight find_elements |
| 187â€“194 | `if not results: break` â€”kalau nggak nemu hasil, program berhenti. Ini safety check biar nggak error. | Highlight if not results |
| 195â€“202 | Terus ada loop `for result in results` â€”ini buat ambil data dari setiap rumah sakit satu per satu. | Highlight for loop |
| 203â€“210 | `name = result.find_element(By.CLASS_NAME, 'dbg0pd').text` â€”ambil nama rumah sakit dari class 'dbg0pd'. | Highlight nama |
| 211â€“218 | `address = result.find_element(By.CLASS_NAME, 'rllt__details')...` â€”ambil alamat dari class 'rllt__details', terus ambil div kedua. | Highlight alamat |
| 219â€“226 | `rating = result.find_element(By.CLASS_NAME, 'OSrXXb').text` â€”ambil rating dari class 'OSrXXb'. | Highlight rating |
| 227â€“230 | `link = result.find_element(By.CLASS_NAME, 'yYlJEf').get_attribute('href')` â€”ambil link website dari class 'yYlJEf'. | Highlight link |

---

### **CHAPTER 5: Navigate ke Halaman Berikutnya (230â€“260 detik)**

| Waktu | Narasi | Visual |
|-------|--------|--------|
| 230â€“237 | Setelah ambil semua data di halaman ini, program coba cari tombol "Next" buat lanjut ke halaman berikutnya. | Gesture "next page" |
| 238â€“245 | `next_button = driver.find_element(By.ID, 'pnnext')` â€”cari tombol Next pake ID 'pnnext'. Ini ID khusus Google buat tombol next. | Highlight next_button |
| 246â€“253 | `next_button.click()` â€”klik tombol Next! Terus `time.sleep(3)` lagi buat tunggu halaman baru loading. | Highlight click() |
| 254â€“260 | Kalau tombol Next nggak ketemu (artinya udah di halaman terakhir), program print "No more pages" terus break dari loop. | Highlight except block |

---

### **CHAPTER 6: Export ke CSV â€” Simpan Datanya! (260â€“290 detik)**

| Waktu | Narasi | Visual |
|-------|--------|--------|
| 260â€“267 | Setelah semua data terkumpul, sekarang waktunya export! Kita pake library CSV bawaan Python. | Gesture "export" |
| 268â€“275 | `with open('hospital_data_selenium.csv', 'w', encoding='utf-8') as file` â€”buka file CSV baru, mode write, encoding UTF-8 biar karakter Indonesia nggak error. | Highlight open() |
| 276â€“283 | `writer = csv.DictWriter(file, fieldnames=['name', 'address', 'rating', 'link'])` â€”setup writer dengan 4 kolom: nama, alamat, rating, link. | Highlight DictWriter |
| 284â€“288 | `writer.writeheader()` â€”tulis header kolom di baris pertama. | Highlight writeheader() |
| 289â€“290 | `for result in all_results: writer.writerow(result)` â€”loop semua data, tulis ke CSV satu per satu. | Highlight writerow() |

---

### **CHAPTER 7: Jalankan & Lihat Hasilnya! (290â€“320 detik)**

| Waktu | Narasi | Visual |
|-------|--------|--------|
| 290â€“298 | Oke, kode udah siap. Sekarang tinggal jalanin! Buka terminal, ketik: `python scrape_hospital.py` â€”enter! | Ketik di terminal |
| 299â€“306 | Browser Chrome bakal terbuka otomatis, terus pergi ke Google Maps, mulai scrape data rumah sakit satu per satu. | Tunjuk browser yang jalan |
| 307â€“314 | Lo bisa liat prosesnya: scroll otomatis, klik tombol Next, ambil data... semua jalan sendiri kayak robot! | Gesture "otomatis" |
| 315â€“320 | Setelah selesai, browser otomatis tutup, dan muncul file baru namanya `hospital_data_selenium.csv`. | Tunjuk file CSV |

---

### **CHAPTER 8: Lihat Data di Excel/Google Sheets (320â€“350 detik)**

| Waktu | Narasi | Visual |
|-------|--------|--------|
| 320â€“327 | Buka file CSV-nya pake Excel atau Google Sheets. Lo bakal liat semua data rapih dalam tabel: nama, alamat, rating, link website. | Buka Excel/Sheets |
| 328â€“335 | Tinggal sortir, filter, atau export ke format lain. Mau jadi database? Tinggal import ke MySQL atau MongoDB. | Gesture "database" |
| 336â€“343 | Bayangin kalau lo harus manual copy-paste 100 rumah sakit... bisa berjam-jam! Dengan script ini? 2 menit selesai. | Gesture "cepet banget" |
| 344â€“350 | *(jeda napas)* | Tatap kamera, ekspresi "keren kan?" |

---

### **CHAPTER 9: Use Cases â€” Buat Apa Sih Ini? (350â€“390 detik)**

| Waktu | Narasi | Visual |
|-------|--------|--------|
| 350â€“357 | "Terus... buat apa sih scrape data rumah sakit?" Pertanyaan bagus! Ini beberapa use case-nya: | Hitung pakai jari |
| 358â€“365 | **Pertama: Riset pasar kesehatan.** Buat startup kesehatan? Lo butuh data kompetitorâ€”rumah sakit mana aja yang ada di daerah lo. | Gesture "riset" |
| 366â€“373 | **Kedua: Database publik.** Buat website direktori rumah sakit? Lo bisa update data otomatis tiap minggu pake script ini. | Gesture "website" |
| 374â€“381 | **Ketiga: Analisis lokasi.** Mau buka klinik baru? Cek dulu rumah sakit kompetitor di sekitar lokasi target. | Gesture "analisis" |
| 382â€“387 | **Keempat: Emergency app.** Buat aplikasi darurat yang butuh data rumah sakit terdekatâ€”update otomatis! | Gesture "app" |
| 388â€“390 | *(jeda napas)* | Angguk pelan |

---

### **CHAPTER 10: Warning & Etika (390â€“420 detik)**

| Waktu | Narasi | Visual |
|-------|--------|--------|
| 390â€“398 | TAPIâ€”ada beberapa hal yang harus lo inget. Pertama: jangan scrape terlalu cepat atau terlalu banyak. Google bisa block IP lo. | Gesture "stop" |
| 399â€“406 | Kedua: tambah `time.sleep()` yang cukup antar halamanâ€”minimal 3 detik biar nggak kayak bot spam. | Highlight time.sleep |
| 407â€“414 | Ketiga: jangan gunain buat hal ilegalâ€”spam, phising, atau jual data tanpa izin. Etika, bro! | Ekspresi serius |
| 415â€“420 | Keempat: cek Terms of Service Google. Scraping untuk riset pribadi biasanya okay, tapi untuk komersial bisa kena masalah. | Geleng kepala |

---

### **CLOSING & CALL TO ACTION (420â€“440 detik)**

| Waktu | Narasi | Visual |
|-------|--------|--------|
| 420â€“427 | Jadi... sekarang lo udah tau cara scrape data rumah sakit dari Google Maps otomatis pake Python + Selenium. Gampang kan? | Senyum |
| 428â€“433 | Coba praktekin sendiriâ€”ambil data restoran, hotel, atau toko di daerah lo. Tinggal ganti keyword di URL-nya aja! | Gesture "coba sekarang" |
| 434â€“438 | Kalau berhasil, komen di bawah! Share juga data apa yang lo scrapeâ€”siapa tau bisa jadi referensi buat yang lain. | Tunjuk kolom komentar |
| 439â€“440 | Sampai jumpa di video berikutnya! | Wave tangan |

---

## ğŸ“ FULL CODE YANG SUDAH DIJELASKAN

```python
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager

import time
import csv

# Setup WebDriver
# options = webdriver.ChromeOptions()
# options.add_argument("--headless")  # Operasikan di background tanpa membuka browser
# driver = webdriver.Chrome(options=options)

# Set up Selenium WebDriver
options = webdriver.ChromeOptions()
# Uncomment next line for headless mode
# options.add_argument("--headless")  
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

# URL yang akan diambil datanya
url = 'https://www.google.com/search?q=rs+di+Sumatera+Utara&sca_esv=3539a24babae7179&biw=1745&bih=828&tbm=lcl&ei=xgNYZ6PcJ72V4-EPgqny8Aw&ved=0ahUKEwij1_f865yKAxW9yjgGHYKUHM4Q4dUDCAk&uact=5&oq=rs+di+Sumatera+Utara&gs_lp=Eg1nd3Mtd2l6LWxvY2FsIhRycyBkaSBTdW1hdGVyYSBVdGFyYTIFEAAYgAQyBhAAGBYYHjIGEAAYFhgeMgYQABgWGB4yBhAAGBYYHjIGEAAYFhgeMgYQABgWGB4yBhAAGBYYHjIGEAAYFhgeMgYQABgWGB5I1iBQ5AVYqRxwAHgAkAEBmAGxAaABvQ-qAQQ2LjEzuAEDyAEA-AEB-AECmAIGoAKLBcICCBAAGIAEGKIEwgIFECEYoAHCAggQABgWGAoYHpgDAIgGAZIHAzMuM6AH0UA&sclient=gws-wiz-local#rlfi=hd:;si:;mv:[[3.7209831999999996,98.890147],[3.4804415,98.474175]];tbs:lrf:!1m4!1u3!2m2!3m1!1e1!1m4!1u2!2m2!2m1!1e1!2m1!1e2!2m1!1e3!3sIAE,lf:1,lf_ui:2'

# Buka URL
driver.get(url)
time.sleep(3)  # Tunggu beberapa detik supaya halaman sepenuhnya dimuat

# Inisialisasi untuk menyimpan data yang diambil
all_results = []

# Loop untuk mengambil data dari beberapa halaman
while True:
    # Ambil elemen hasil pencarian rumah sakit
    results = driver.find_elements(By.CLASS_NAME, 'VkpGBb')
    if not results:
        print("No results found.")
        break
    
    # Loop untuk mengambil setiap hasil dari halaman
    for result in results:
        # Mengambil nama rumah sakit
        name = result.find_element(By.CLASS_NAME, 'dbg0pd').text if result.find_element(By.CLASS_NAME, 'dbg0pd') else 'No Name'
        
        # Mengambil alamat rumah sakit
        address = result.find_element(By.CLASS_NAME, 'rllt__details').find_elements(By.TAG_NAME, 'div')[1].text if result.find_element(By.CLASS_NAME, 'rllt__details') else 'No Address'
        
        # Mengambil rating rumah sakit
        rating = result.find_element(By.CLASS_NAME, 'OSrXXb').text if result.find_element(By.CLASS_NAME, 'OSrXXb') else 'No Rating'
        
        # Mengambil link website rumah sakit
        link = result.find_element(By.CLASS_NAME, 'yYlJEf').get_attribute('href') if result.find_element(By.CLASS_NAME, 'yYlJEf') else 'No Link'
        
        # Menyimpan hasil dalam list
        all_results.append({
            'name': name,
            'address': address,
            'rating': rating,
            'link': link
        })
    
    # Mencari tombol "Next" untuk halaman selanjutnya
    try:
        next_button = driver.find_element(By.ID, 'pnnext')
        next_button.click()
        print("Next page found, scraping...")
        time.sleep(3)  # Beri waktu 3 detik untuk memuat halaman berikutnya
    except:
        # Jika tidak ada tombol "Next", berarti kita sudah di halaman terakhir
        print("No more pages found. Scraping finished.")
        break

# Menyimpan data ke dalam file CSV
with open('hospital_data_selenium.csv', mode='w', newline='', encoding='utf-8') as file:
    writer = csv.DictWriter(file, fieldnames=['name', 'address', 'rating', 'link'])
    writer.writeheader()  # Menulis header kolom
    
    # Menulis setiap hasil ke dalam file CSV
    for result in all_results:
        writer.writerow(result)

print("Data telah disimpan ke dalam 'hospital_data_selenium.csv'.")

# Tutup driver setelah selesai
driver.quit()
```

---

## ğŸ¯ TIPS TAMBAHAN

### **Install Library:**
```bash
pip install selenium
pip install webdriver-manager
```

### **Jalankan Script:**
```bash
python scrape_hospital.py
```

### **Contoh Hasil CSV:**
```csv
name,address,rating,link
RSU Dr. Pirngadi,Medan,+100,+62611234567,https://rsupirngadi.com
RS Columbia Asia,Medan,+500,+62619876543,https://columbiaasia.com
RS Mitra Sejati,Medan,+300,+62614567890,https://mitrasejati.com
```

### **Cara Ganti Keyword Pencarian:**
Ganti bagian `q=rs+di+Sumatera+Utara` di URL dengan:
- `q=restoran+di+Jakarta` â†’ scrape restoran
- `q=hotel+di+Bali` â†’ scrape hotel
- `q=toko+kelontong+di+Bandung` â†’ scrape toko

### **Mode Headless (Tanpa Browser Terbuka):**
Uncomment baris ini buat bikin lebih cepat:
```python
options.add_argument("--headless")
```

---

## âš ï¸ IMPORTANT NOTES

1. **Jangan scrape terlalu cepat** â€” tambah `time.sleep(5)` atau lebih untuk hindari rate limiting
2. **Google bisa block IP** jika terdeteksi bot â€” gunakan proxy jika perlu
3. **Class name bisa berubah** â€” Google sering update HTML, jadi class seperti 'VkpGBb' mungkin berubah
4. **Untuk produksi**, tambahkan error handling yang lebih baik dan logging
5. **Hormati Terms of Service** â€” jangan gunakan untuk spam atau aktivitas ilegal

---

## ğŸ”§ TROUBLESHOOTING

### **Error: "ChromeDriver not found"**
Pastikan udah install webdriver-manager:
```bash
pip install webdriver-manager
```

### **Error: "Element not found"**
Class name Google mungkin udah berubah. Inspect element di browser buat cari class name baru.

### **Script jalan tapi nggak nemu data**
- Tambah `time.sleep()` lebih lama (5-10 detik)
- Cek apakah website udah kebuka dengan benar
- Coba matikan ad blocker atau VPN

---

## ğŸ¬ JUDUL & DESKRIPSI YOUTUBE (Clickbait Style)

**Judul:**  
CARA SCRAPE DATA RUMAH SAKIT DARI GOOGLE MAPS OTOMATIS! (Python + Selenium)

**Deskripsi:**  
Gue bakal kasih tau cara ambil data rumah sakit dari Google Mapsâ€”otomatis, tanpa manual copy-paste! Dalam video ini, lo bakal belajar:  
âœ… Setup Python + Selenium + ChromeDriver  
âœ… Scraping data rumah sakit di Sumatera Utara  
âœ… Navigate otomatis ke halaman berikutnya  
âœ… Export data ke CSV (Excel/Google Sheets)  
âœ… Cara ganti keyword buat scrape restoran, hotel, dll  
âœ… Tips & warning yang harus lo tau  

Tools yang dipake: Python + Selenium + webdriver-manager. 100% gratis & powerful!

#webscraping #python #selenium #datascience #tutorial #programming #automation
